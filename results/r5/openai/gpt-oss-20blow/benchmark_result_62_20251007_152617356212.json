{
  "benchmark_config": {
    "benchmark_id": "62_2025-10-07T15:26:17.356200",
    "jira_id": "62",
    "jira_title": "Implement/Test API: GET /1.0/kb/bundles/search/{searchKey} - Search bundles",
    "benchmark_status": "completed",
    "total_run": 1,
    "total_passed": 1,
    "total_failed": 0
  },
  "test_config": {
    "benchmark_start_time": "2025-10-07T15:26:07.609328",
    "benchmark_end_time": "2025-10-07T15:26:17.356198",
    "framework": "analyze_gherkin_folder",
    "device": "Apple M3 Max",
    "llm_config": {
      "model": "openai/gpt-oss-20b",
      "temperature": 0.0,
      "max_tokens": 16384,
      "seed": -1
    }
  },
  "benchmark_results": {
    "average_coverage_percentage": 71,
    "average_generation_time_seconds": 9.74687,
    "benchmark_output": [
      {
        "average_coverage_percentage": 71,
        "generation_time_seconds": 0.0,
        "generated_output_count": 1,
        "status": "completed",
        "gherkin_id": "62_qe_sup-gpt4.1_agent-gpt4.1_1748919997.feature",
        "coverage_analysis": [
          {
            "coverage_percentage": 71,
            "covered": [
              "Valid Request: Scenarios cover successful retrieval of bundles.",
              "Empty Response: Scenarios for no bundles and empty database.",
              "Pagination: Scenarios test offset and limit handling.",
              "Query Parameters: Scenarios test audit, offset, limit, invalid values, extra params.",
              "Authorization: Scenarios test missing and invalid auth tokens."
            ],
            "gaps": [
              "Rate Limiting: No tests cover rate limiting behavior.",
              "Caching Behavior: No tests cover caching headers like ETag or Cache-Control."
            ],
            "recommendations": [
              "Add tests for rate limiting to ensure system handles multiple requests in short time.",
              "Add tests for caching behavior, checking ETag and Cache-Control headers."
            ],
            "usage": {
              "completion_tokens": 1740,
              "prompt_tokens": 5100,
              "total_tokens": 6840
            }
          }
        ]
      }
    ]
  }
}