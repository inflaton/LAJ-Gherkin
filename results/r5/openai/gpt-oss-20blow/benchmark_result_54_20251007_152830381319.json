{
  "benchmark_config": {
    "benchmark_id": "54_2025-10-07T15:28:30.381234",
    "jira_id": "54",
    "jira_title": "Implement/Test API: DELETE /1.0/kb/bundles/{bundleId}/tags - Remove tags from bundle",
    "benchmark_status": "completed",
    "total_run": 1,
    "total_passed": 1,
    "total_failed": 0
  },
  "test_config": {
    "benchmark_start_time": "2025-10-07T15:27:42.448138",
    "benchmark_end_time": "2025-10-07T15:28:30.381215",
    "framework": "analyze_gherkin_folder",
    "device": "Apple M3 Max",
    "llm_config": {
      "model": "openai/gpt-oss-20b",
      "temperature": 0.0,
      "max_tokens": 16384,
      "seed": -1
    }
  },
  "benchmark_results": {
    "average_coverage_percentage": 75,
    "average_generation_time_seconds": 47.933077,
    "benchmark_output": [
      {
        "average_coverage_percentage": 75,
        "generation_time_seconds": 0.0,
        "generated_output_count": 1,
        "status": "completed",
        "gherkin_id": "54_qe_sup-gpt4.1_agent-gpt4.1_1748919454.feature",
        "coverage_analysis": [
          {
            "coverage_percentage": 75,
            "covered": [
              "Valid Deletion: Successful removal of tags is thoroughly tested across multiple scenarios.",
              "Non-Existent Resource: Tests verify 404 response for missing bundle.",
              "Concurrency: Concurrent delete requests are tested for race conditions."
            ],
            "gaps": [
              "Soft Deletes: No tests verify that tags are soft-deleted or marked as deleted rather than permanently removed."
            ],
            "recommendations": [
              "Add a test scenario that deletes tags and then checks that the tags are marked as deleted (e.g., a \"deleted\" flag) rather than removed from the database, to cover soft delete behavior."
            ],
            "usage": {
              "completion_tokens": 1393,
              "prompt_tokens": 5039,
              "total_tokens": 6432,
              "completion_tokens_details": {
                "reasoning_tokens": 1246
              }
            }
          }
        ]
      }
    ]
  }
}