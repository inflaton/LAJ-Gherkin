{
  "benchmark_config": {
    "benchmark_id": "83_2025-09-28T02:43:26.161776",
    "jira_id": "83",
    "jira_title": "Implement/Test API: GET /1.0/kb/customFields/search - Search custom fields by type, name and optional value",
    "benchmark_status": "completed",
    "total_run": 1,
    "total_passed": 1,
    "total_failed": 0
  },
  "test_config": {
    "benchmark_start_time": "2025-09-28T02:43:21.592770",
    "benchmark_end_time": "2025-09-28T02:43:26.161773",
    "framework": "analyze_gherkin_folder",
    "device": "Apple M3 Max",
    "llm_config": {
      "model": "gpt-5-nano",
      "temperature": 1.0,
      "max_tokens": 10000,
      "seed": -1
    }
  },
  "benchmark_results": {
    "average_coverage_percentage": 71,
    "average_generation_time_seconds": 4.569003,
    "benchmark_output": [
      {
        "average_coverage_percentage": 71,
        "generation_time_seconds": 0.0,
        "generated_output_count": 1,
        "status": "completed",
        "gherkin_id": "83_qe_sup-gpt4.1_agent-gpt4.1_1748921300.feature",
        "coverage_analysis": [
          {
            "coverage_percentage": 71,
            "covered": [
              "Valid Request",
              "Empty Response",
              "Pagination",
              "Query Parameters",
              "Authorization"
            ],
            "gaps": [
              "Rate Limiting",
              "Caching Behavior"
            ],
            "recommendations": [
              "Add tests for rate limiting/throttling to ensure multiple requests are handled correctly and within limits.",
              "Add tests for caching behavior, such as validating ETag/Cache-Control headers and cacheability of responses."
            ],
            "usage": {
              "completion_tokens": 754,
              "prompt_tokens": 6532,
              "total_tokens": 7286,
              "completion_tokens_details": {
                "accepted_prediction_tokens": 0,
                "audio_tokens": 0,
                "reasoning_tokens": 640,
                "rejected_prediction_tokens": 0
              },
              "prompt_tokens_details": {
                "audio_tokens": 0,
                "cached_tokens": 0
              }
            }
          }
        ]
      }
    ]
  }
}