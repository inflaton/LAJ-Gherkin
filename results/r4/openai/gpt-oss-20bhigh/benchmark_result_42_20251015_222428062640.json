{
  "benchmark_config": {
    "benchmark_id": "42_2025-10-15T22:24:28.062612",
    "jira_id": "42",
    "jira_title": "Implement/Test API: GET /1.0/kb/admin/queues - Get queues entries",
    "benchmark_status": "completed",
    "total_run": 1,
    "total_passed": 1,
    "total_failed": 0
  },
  "test_config": {
    "benchmark_start_time": "2025-10-15T22:24:22.862473",
    "benchmark_end_time": "2025-10-15T22:24:28.062606",
    "framework": "analyze_gherkin_folder",
    "device": "Unknown",
    "llm_config": {
      "model": "openai/gpt-oss-20b",
      "temperature": 0.0,
      "max_tokens": 16384,
      "seed": -1
    }
  },
  "benchmark_results": {
    "average_coverage_percentage": 57,
    "average_generation_time_seconds": 5.200133,
    "benchmark_output": [
      {
        "average_coverage_percentage": 57,
        "generation_time_seconds": 0.0,
        "generated_output_count": 1,
        "status": "completed",
        "gherkin_id": "42_qe_sup-gpt4.1_agent-gpt4.1_1748918658.feature",
        "coverage_analysis": [
          {
            "coverage_percentage": 57,
            "covered": [],
            "gaps": [
              "Pagination: No tests cover page size, page number or offset handling for large result sets.",
              "Rate Limiting: The API is not exercised under rapid successive requests to verify throttling or 429 responses.",
              "Caching Behavior: No scenarios check for ETag, Cache\u2011Control or other caching headers."
            ],
            "recommendations": [
              "Add pagination tests that request specific page sizes and verify correct subset of results and pagination metadata.",
              "Create rate\u2011limiting tests that send many rapid requests and assert a 429 or appropriate throttling response.",
              "Include caching tests that validate the presence and correctness of ETag, Cache\u2011Control, and Last\u2011Modified headers for GET responses."
            ],
            "usage": {
              "completion_tokens": 1521,
              "prompt_tokens": 6093,
              "total_tokens": 7614
            }
          }
        ]
      }
    ]
  }
}